---
title: "Car MPG"
author: "ccf"
date: "January 17, 2016"
output: 
  html_document: 
    keep_md: yes
---

This is an R markdown file for the car mpg data shown in class.  We will reporduce some of the SAS output using R and Rstudio.

First we need to read the data into R.

```{r}
carmpg <- read.table("~/Documents/MATH3710/cars/MPGData.txt", header = TRUE)
summary(carmpg)
cor(carmpg)
```


Above are simple summary statistics of the data.

Now let's look at a scatter plot of the data.

```{r}
plot(MPG ~ Weight, data=carmpg, bg = "lightblue", 
     col = "black", cex = 1.5, pch = 21)
text(x=1800, y=15, paste0("Cor = ",round(cor(carmpg)[2], 4), cex = 0.7))
```


Now we fit a linear model in R using the lm function. We will store it in a variable for more use.

```{r}
fit <- lm(MPG ~ Weight, data = carmpg)
summary(fit) # displays a summary of the model.
```


Now we will use R to check the assumptions of the model. First we will store the standardized residuals from "fit" and store them in a variable.

```{r}
e <- rstandard(fit)
summary(e)
```

More diagnostic plots of our model:
```{r}
qqnorm(e)
qqline(e)
# Residuals vs. x
x <- carmpg$Weight
plot(x, e, bg = "lightblue", 
     col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(h = 0, lwd = 2)
```

One more plot.  Here we will look at a histogram of the residuals.

```{r}
hist(e, breaks = 25, col = "green", freq = FALSE, xlim = c(-4,4), 
     main = "Histogram of Standardized Residuals", xlab = "rstandard")
```

Now we want to test our model.  We will take a sample of size 30 and call it "test".  The remaining 259 obs will be used to build our new model.

```{r}
carmpg$index <- 1:289
# first lets create an simple random sample of numbers.  We will use this to sample
# and subset the original car mpg data set.
ind <- sample(1:289, 30)
# now we can subset the carmpg data frame into 2 data frames using this index.
test <- carmpg[carmpg$index %in% ind, ]
#test <- read.csv("~/Documents/MATH3710/cars/test.csv")
training <- carmpg[!(carmpg$index %in% ind), ]
#training <- read.csv("~/Documents/MATH3710/cars/training.csv")
# now to fit a new model with our subsetted training data.
fit2 <- lm(MPG ~ Weight, data = training)
testing <- predict(fit2, newdata = test, interval = "confidence", se.fit = TRUE)
anova(fit2)
# SAS proc score is different from R predict() but essetially predict() is testing
# your training model with your test data.
# here is the predicted bias:
predicted_bias <- mean(test$MPG - testing$fit[,1])
mean_square_bias <- mean((test$MPG - testing$fit[,1])^2)
rpmse <- sqrt(mean_square_bias)
output <- as.data.frame(cbind(predicted_bias, mean_square_bias, rpmse))
output
```

Let's take this further by bootstrapping our predicted bias...This will be a challenge programatically but if we take it one step at a time we should be able to do it. Let's generate 100 random predicted bias estimates.

```{r}
bias <- vector()
for (i in 1:100) {
  ind <- sample(1:289, 30)
  # now we can subset the carmpg data frame into 2 data frames using this index.
  test <- carmpg[carmpg$index %in% ind,]
  training <- carmpg[!(carmpg$index %in% ind),]
  # now to fit a new model with our subsetted training data.
  fit2 <- lm(MPG ~ Weight, data = training)
  testing <- predict.lm(fit2, newdata = test)
  # here is the predicted bias:
  predicted_bias <- mean(test$MPG - testing)
  bias <- rbind(bias, predicted_bias)
}
mean(bias)
hist(bias, col = "green")
```
