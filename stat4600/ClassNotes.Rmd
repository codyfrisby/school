---
title: "Class Notes"
output: 
  pdf_document: 
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', dpi=200)
library(qcc); library(SixSigma); library(qualityTools)
old <- qcc.options()
qcc.options(bg.margin = "white")
```

HW 1, Chapter 1: 3, 4, 5, 6, 9, 10, 14, 19:

1.3 Select a specific product or service, and discuss how the eight dimensions of quality impact its overall acceptance by consumers.

- Performance
- Reliability
- Durability
- Servicability
- Aesthetics
- Features
- Percieved Quality
- Conformance to Standards

1.4 Is there a difference between quality for a manufactured product and quality for a service? Give some specific examples.

Some of the 8 dimensions of quality above might be more important for a manufactured product than a service and vice versa. Having said that, the principals of quality and quality improvement are applicable and appliable to manufacturing and service industries.

1.5 Can an understanding of the multidimensional nature of quality lead to improved product design or better service?

Yes. By undertanding sources of variation in a product or the manufacturing of that product (or delierving of a service) we can "design" quality into the product or service.

1.6 What are the internal customers of a business? Why are they important from a quality perspective?

The "downstream" departments or areas are an example of an internal customer. They are the recipients of what we produce. If we produce poor quality product/service they have to work with an already poor quality product/service.

1.9 What are the three primary technical tools used for quality control and improvement?

- Statistical Process Control (SPC)
- Design of Experiments (DOE)
- Acceptance Sampling

1.10 Distinguish among quality planning, quality assurance, and quality control and improvement.

Planning is a strategic activity. Identifiying needs of internal and external customers -aka Voice of the Customer (VOC). Assurance is the set of activities that ensures quality levels are properly maintained - documention is an example. Control & Improvement are the sets of activites that ensure prodcuts/services meet specs and are continuously improved.

1.14 Are internal failure costs more or less important than external failure costs?

Internal failures are probably cheaper, but understanding and eliminating them is MORE important. It is much more costly for failures to be found or occur externally.

1.19 Most of the quality management literature states that without top management leadership, quality improvement will not occur. Do you agree or disagree with this statement? Discuss why.

Yes. Management must be involved in improvement activities. Often, workers do not have the time on the job to initiiate improvement activities even though they may be the most familiar with the activites that need improvemnt. It must be two-sided with management and worker collaborating together.

8/31/16

Acceptance Sampling
Statistical Process Control (online)
Design of Experiments (offline)
Distinction between Obeservation and Experiment. Treatment assignment - Randomized or confounded?

Leverage, if you fix something internally it has a multiplier affect - that if you fix something now it will help you in the long run.

9/2/16

What is a causal effect?

Correlation is NOT causation BUT the lack of correlation DOES NOT mean NO causation.

In the catagorical setting, association is not causation.

$$E(Y_{x=1} - Y_{x=0})$$

Potential Outcomes
Counterfactual reasoning (unobserved)
HW Ch 2: 1-8.

2.1. Discuss the similarities between the Shewhart cycle and DMAIC.

2.2. Describe a service system that you use. What are the CTQs that are important to you? How do you think that DMAIC could be applied to this process?

2.3. One of the objectives of the control plan in DMAIC is to “hold the gain.” What does this mean?

When you make gains from an improvement process things can got back to the "way they were" if you don't sustain. The control phase of DMAIC is just that, control or sustain the gains you've made. This can be done through standardization or training among other methods.

2.4. Is there a point at which seeking further improve- ment in quality and productivity isn’t economically advisable? Discuss your answer.

2.5. Explain the importance of tollgates in the DMAIC process.

2.6. An important part of a project is to identify the key process input variables (KPIV) and key process output variables (KPOV). Suppose that you are the owner/manager of a small business that provides mailboxes, copy services, and mailing services. Discuss the KPIVs and KPOVs for this business. How do they relate to possible customer CTQs?

2.7. An important part of a project is to identify the key process input variables (KPIV) and key process out- put variables (KPOV). Suppose that you are in charge of a hospital emergency room. Discuss the KPIVs and KPOVs for this business. How do they relate to possible customer CTQs?

2.8. Why are designed experiments most useful in the improve step of DMAIC?

Chapter 3

# copy and paste data into R, rJava is broken so xlsx doesn't work
library(psych)
# copy your data first, then:
if(interactive()){ # ignores this bit when knitting.  
  df <- read.clipboard()
  write.csv(df, "df.csv")
}
# continue on
if(file.exists("df.csv")){
  df <- read.csv("df.csv")
}
9/21/16

x <- rexp(100)
par(mfrow=c(1,2))
stripchart(x)
hist(x, col="green")
Ch. 3 HW: 3.1-3.10

9/23/16

Random Sample
$\chi^2$
Chapter 4 HW:

4.5,6,9,11,12,13,14,15,17,19,26, DUE 9-30-16

4.29,33,34,35 DUE 10-7-16

EXAM 1

Due 10-7-16 start of class

Pick one of the following:

Use R to conduct simulaitons to assess the sensitivity of ANOVA to departures from assumptions (normality, sample sizes, etc.)

Use the fact that Fn ---> F along with resampling and compare with a method from the book. (NOTE: Fn is the empirical CDF. F is the theoretical CDF. Here we can bootstrap the observed data. "Our best guess is that the sample distribution IS the population distribution." This one is a bootstrapping problem :))

Assume i.i.d normality. Let $$\lambda = \frac{L(x; H_0)}{L(x; H_A)}$$ where $H_0: \mu = 0, \sigma = 1$ and $H_A: \mu = \mu_a$ and $\sigma = \sigma_a$. Which distributions (specified by f($\mu_a$, $\sigma_a$)) lead to $\int \lambda f = h(x)$ being small precisely when $t = \frac{\bar x - 0}{\frac{s}{\sqrt{n}}}$ is extreme?

Research and explain how Bayes Factors can produce a posterior distribution for a prior distribution.

## chapter 6 HW
1-5  

We are going to be replacing experience with simulation.
Steps:
* Set n = 1, 5, 10.
* Produce k = 30 or 100 (you choose whatever you want) samples of size n. – according to proposed schemes (clustered or random) * generate N >> nk observations (iid ~ N($\mu$, $\sigma$).
* introduce an assignable cause via unif(0, N).
– Drop size
– return time
– trend
– etc.
– don’t muck around with the variance.


### Chapter 9 HW:  
1,2,9,18,19

```{r, fig.height=6}
# example 9.1
x <- c(9.45,7.99,9.29,11.66,12.16,10.18,8.04,11.46,9.2,10.34,9.03,11.47,
       10.51,9.4,10.08,9.37,10.62,10.31,8.52,10.84,10.9,9.33,12.29,
       11.5,10.6,11.08,10.38,11.62,11.31,10.52)
cu <- cusum(x, center = 10, std.dev = 1)
C <- cumsum(x - 10)
s <- 1; mu <- 10; k <- s/2
x.mu <- x - mu; C <- cumsum(x.mu)
xplus <- x - (mu + k)
xminus <- (mu - k) - x
cplus <- pmax(0, xplus)
df <- data.frame(x, x.mu, C, xplus, xminus, Cplus = cu$pos, 
                 Cminus = cu$neg)
knitr::kable(df)
```

```{r, fig.height=6}
# standardized cusum
y <- (x - mean(x))/sd(x)
s <- qcc(y, type = "xbar.one", plot = F)$std.dev
mu <- qcc(y, type = "xbar.one", plot = F)$center
cu <- cusum(y, center = mu, std.dev = s, se.shift = 1/2, 
            decision.interval = 5)
```


### EWMA  

```{r, fig.height=6}
# using the same data above...:
cc <-ewma(x, center = 10, std.dev = 1, lambda = 0.1, nsigmas = 2.7)
```


```{r}
# reproducing Table 9.10 on page 421, 6th ed.
data.frame(subgroup = cc$x, xi = cc$data, zi = cc$y)
```


```{r}
# really cool simulation from class:  
x <- rnorm(100)
y <- numeric(100)
y[1] <- 0
weight <- 0.9
for(i in 2:100){
  y[i] <- y[i-1] + weight * (x[i] - y[i-1])
}
plot(y)
# the smaller the weight the more "non-random" y becomes
```


## Chapter 15 HW, due:
1-8  
